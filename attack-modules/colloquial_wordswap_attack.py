import random

from moonshot.src.redteaming.attack.attack_module import AttackModule
from moonshot.src.redteaming.attack.attack_module_arguments import AttackModuleArguments
from moonshot.src.utils.log import configure_logger
from nltk import word_tokenize
from nltk.tokenize.treebank import TreebankWordDetokenizer

# Create a logger for this module
logger = configure_logger(__name__)


class ColloquialWordSwapAttackModule(AttackModule):
    def __init__(self, am_id: str, am_arguments: AttackModuleArguments | None = None):
        # Initialize super class
        super().__init__(am_id, am_arguments)
        self.name = "Colloquial Wordswap"
        self.description = (
            "This attack module tests for textual robustness against the Singapore context. It takes in prompts that "
            "feature nouns that describe people. Examples of this include words like 'girl' , 'boy' or 'grandmother'. "
            "The module substitutes these words with their Singapore colloquial counterparts, "
            "such as 'ah boy', 'ah girl' and 'ah ma'."
        )

    def get_metadata(self) -> dict:
        """
        Get metadata for the attack module.

        Returns:
            dict | None: A dictionary containing the 'id', 'name', 'description', 'endpoints' and 'configurations'
            or None if the metadata is not available.
        """
        endpoints = self.req_and_config.get("endpoints", [])
        configurations = self.req_and_config.get("configurations", {})

        return {
            "id": self.id,
            "name": self.name,
            "description": self.description if hasattr(self, "description") else "",
            "endpoints": endpoints,
            "configurations": configurations,
        }

    async def execute(self):
        """
        Asynchronously executes the attack module.

        This method loads the dataset contents using the `load_dataset_contents` method,
        processes the dataset through a prompt template, retrieves the connector to the first
        Language Learning Model (LLM) and sends the processed dataset as a prompt to the LLM.
        """
        self.load_modules()
        return await self.perform_attack_manually()

    async def perform_attack_manually(self) -> list:
        """
        Asynchronously performs the attack manually. The user will need to pass in a list of prompts and
        the LLM connector endpoint to send the prompts to. In this example, there is a for loop to send the
        list of prepared prompts to all the LLM connectors defined.

        This method prepares prompts for each target Language Learning Model (LLM) using the provided prompt
        and sends them to the respective LLMs.
        """
        """
        This is the dictionary that is used to swap words.
        """
        colloquial_dict = {
            "father": ["papa", "lao bei", "lim pei", "bapa", "appa"],
            "mother": ["mama", "amma", "ibu"],
            "grandfather": ["ah gong", "thatha", "dato"],
            "grandmother": ["ah ma", "patti", "nenek"],
            "girl": ["ah ger", "ponnu"],
            "boy": ["ah boy", "boi", "payyan"],
            "son": ["ah boy", "boi", "payyan"],
            "daughter": ["ah ger", "ponnu"],
            "aunt": ["makcik", "maami"],
            "aunty": ["makcik", "maami"],
            "man": ["ah beng", "shuai ge"],
            "woman": ["ah lian", "xiao mei"],
            "uncle": ["encik", "unker"],
            "sister": ["xjj", "jie jie", "zhezhe", "kaka", "akka", "thangatchi"],
            "brother": ["bro", "boiboi", "di di", "xdd", "anneh", "thambi"],
        }
        result_list = []
        # perform word segmentation
        word_list = word_tokenize(self.prompt)
        word_list_len = len(word_list)
        for i in range(word_list_len):
            if word_list[i].lower() in list(colloquial_dict.keys()):
                # randomly select colloquial term
                word_list[i] = word_list[i].lower()
                rand_idx = random.randint(
                    0, len(colloquial_dict[word_list[i].lower()]) - 1
                )
                new_word = colloquial_dict[word_list[i]][rand_idx]
                # check for the same word within the word list
                for j in range(i + 1, word_list_len):
                    if word_list[i].lower() == word_list[j].lower():
                        word_list[j] = new_word
                word_list[i] = new_word
        new_prompt = TreebankWordDetokenizer().detokenize(word_list)
        result_list.append(await self._send_prompt_to_all_llm([new_prompt]))
        word_list = word_tokenize(self.prompt)
        for res in result_list:
            for x in res:
                logger.debug(f"[ColloquialWordSwapAttackModule] Prompt: {x.prompt}")
                logger.debug(
                    f"[ColloquialWordSwapAttackModule] Predicted Results: {x.predicted_results}\n"
                )
        return result_list
