import os
from typing import Any
import json
import logging

from google.cloud import aiplatform
from google.auth import default
from google.auth.transport.requests import Request
import google.auth.transport.requests
import requests
from moonshot.src.connectors.connector import Connector, perform_retry
from moonshot.src.connectors.connector_response import ConnectorResponse
from moonshot.src.connectors_endpoints.connector_endpoint_arguments import (
    ConnectorEndpointArguments,
)

# Set up logging
logger = logging.getLogger(__name__)


class GoogleVertexAIClaudeConnector(Connector):
    def __init__(self, ep_arguments: ConnectorEndpointArguments):
        # Initialize super class
        super().__init__(ep_arguments)

        # Initialize Google Cloud credentials and Vertex AI client
        self.project_id = self.optional_params.get("project_id") or os.getenv("GOOGLE_CLOUD_PROJECT")
        self.region = self.optional_params.get("region", "us-east5")
        
        if not self.project_id:
            raise ValueError("Google Cloud project ID is required. Set GOOGLE_CLOUD_PROJECT environment variable or provide project_id in params.")
        
        # Initialize Vertex AI
        aiplatform.init(project=self.project_id, location=self.region)
        
        # Get credentials for API calls
        self.credentials, _ = default()
        self.credentials.refresh(Request())

    @Connector.rate_limited
    @perform_retry
    async def get_response(self, prompt: str) -> ConnectorResponse:
        """
        Asynchronously sends a prompt to Claude via Google Vertex AI and returns the generated response.

        This method constructs a request with the given prompt, optionally prepended and appended with
        predefined strings, and sends it to Claude via Vertex AI API. The method then processes the response
        and returns the resulting message content wrapped in a ConnectorResponse object.

        Args:
            prompt (str): The input prompt to send to Claude via Vertex AI.

        Returns:
            ConnectorResponse: An object containing the text response generated by Claude.
        """
        logger.debug("========== MODEL INPUT ==========\n")
        logger.debug(f"Original prompt: '{prompt}'\n")
        logger.debug(f"Pre-prompt: '{self.pre_prompt}'\n")
        logger.debug(f"Post-prompt: '{self.post_prompt}'\n")
        logger.debug(f"System prompt: '{self.system_prompt}'\n")
        
        connector_prompt = f"{self.pre_prompt}{prompt}{self.post_prompt}"
        logger.debug(f"Final connector prompt sent to Claude:\n'{connector_prompt}'\n")
        logger.debug("=======================================\n")
        
        # Construct the request payload for Claude
        payload = {
            "anthropic_version": "vertex-2023-10-16",
            "messages": [
                {
                    "role": "user",
                    "content": connector_prompt
                }
            ],
            "max_tokens": self.optional_params.get("max_tokens", 4096),
            "temperature": self.optional_params.get("temperature", 0.5),
        }
        
        # Add system prompt if available
        if self.system_prompt:
            payload["system"] = self.system_prompt

        # Construct the Vertex AI endpoint URL
        endpoint_url = f"https://{self.region}-aiplatform.googleapis.com/v1/projects/{self.project_id}/locations/{self.region}/publishers/anthropic/models/{self.model}:streamRawPredict"
        
        headers = {
            "Authorization": f"Bearer {self.credentials.token}",
            "Content-Type": "application/json; charset=utf-8",
        }
        
        logger.debug("Making API call to Vertex AI...")
        logger.debug(f"Endpoint URL: {endpoint_url}")
        logger.debug(f"Request payload: {json.dumps(payload, indent=2)}")
        
        # Make the API call
        response = requests.post(
            endpoint_url,
            headers=headers,
            json=payload,
            timeout=self.optional_params.get("timeout", 300)
        )
        
        logger.debug(f"API response status: {response.status_code}")
        
        if response.status_code != 200:
            logger.debug(f"API call failed with status {response.status_code}")
            logger.debug(f"Error response: {response.text}")
            raise Exception(f"Vertex AI API call failed with status {response.status_code}: {response.text}")
        
        # Parse the response
        response_data = response.json()
        logger.debug("\n========== MODEL RESPONSE ==========\n")
        logger.debug(f"Raw response from Vertex AI:\n{json.dumps(response_data, indent=2)}\n")
        
        processed_response = await self._process_response(response_data)
        logger.debug(f"Processed Claude response text:\n'{processed_response}'\n")
        logger.debug(f"Response length: {len(processed_response)} characters\n")
        logger.debug("=======================================\n")
        
        return ConnectorResponse(response=processed_response)

    async def _process_response(self, response_data: dict) -> str:
        """
        Process the Vertex AI response and extract the Claude response text.

        Args:
            response_data (dict): The response data from Vertex AI.

        Returns:
            str: The text content from Claude's response.
        """
        try:
            logger.debug("Processing Claude response structure...")
            # Extract the content from Claude's response
            if "content" in response_data and response_data["content"]:
                logger.debug(f"Found 'content' field with {len(response_data['content'])} items")
                content = response_data["content"][0]
                logger.debug(f"First content item: {json.dumps(content, indent=2)}")
                if content.get("type") == "text":
                    text_response = content.get("text", "")
                    logger.debug(f"Extracted text response: '{text_response}'")
                    return text_response
            
            # Fallback for different response formats
            if "text" in response_data:
                logger.debug("Using fallback 'text' field")
                return response_data["text"]
            
            logger.debug("No recognized response format, returning string representation")
            return str(response_data)
            
        except (KeyError, IndexError, TypeError) as e:
            logger.debug(f"Error parsing response: {e}")
            raise Exception(f"Failed to parse Claude response: {e}")