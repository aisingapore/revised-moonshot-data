{
    "name": "Ollama Llama3",
    "connector_type": "openai-connector",
    "uri": "http://localhost:11434/v1/",
    "token": "ollama",
    "max_calls_per_second": 1,
    "max_concurrency": 1,
    "model": "llama3",
    "params": {
        "timeout": 300,
        "max_attempts": 3,
        "temperature": 0.5
    }
}